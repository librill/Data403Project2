---
title: "Model Selection"
output: html_document
date: "2025-11-16"
---

Now that we have evaluated a bunch of models on the training data, it is time
to analyze the performance of the best models on the validation and test sets. 

We have taken the model of each type that performed best on the training set and 
evaluated performance on the validation set. 

The model that performs best on the validation set is our chosen model, 
with metrics reported based on test set performance.

NOTE that no SVC model met our satisficing metric (precision >= 0.6), so we do 
not evaluate its performance on the validation set.

```{r, include=FALSE}
source(here::here("scripts/libraries.R"))
source(here::here("scripts/data_cleaning.R"))
source(here::here("scripts/functions.R"))
source(here::here("scripts/splits.R"))
```

```{r}
strat_splits <- strat_split(df, "TARGET", train_prop = 0.6, val_prop = 0.2, seed = 123)
# undersample the training, not the val and test
train_strat <- undersample_split(strat_splits$train, 0.5)
val_strat <- strat_splits$val
test_strat <- strat_splits$test
```

## Validation Set

### Logistic

```{r}
# define model
logit_mod <- logistic_reg() |>
  set_mode("classification") |>
  set_engine("glm")
```

Best-performing logistic model:

```{r}
lg_rec <- recipe(TARGET ~ ., data = train_strat) |>
  step_rm("SK_ID_CURR") |>
  step_rm("AMT_INCOME_TOTAL") |> 
  step_rm("REGION_POPULATION_RELATIVE") |>
  step_rm("INCOME_TO_CREDIT") |>
  step_rm("CNT_CHILDREN") |>
  step_rm("CONTRACT_TYPE_REVOLVING") |>
  step_rm("INCOME_CLASS_FOURTH") |>
  step_rm("INCOME_CLASS_THIRD") |>
  step_rm("INCOME_CLASS_SECOND") |>
  step_rm("CODE_GENDER") |>
  step_rm("AGE_GROUPS") |>
  step_mutate(TARGET = factor(TARGET, levels=c(0, 1))) |>
  step_dummy(all_nominal_predictors())

logit_wkflow <- workflow() |>
  add_model(logit_mod) |>
  add_recipe(lg_rec)

logistic_fit <- logit_wkflow |>
  fit(train_strat) |>
  extract_fit_parsnip()

preds <- predict(logistic_fit, new_data = val_strat)$.pred_class

val_strat |>
  mutate(predictions = preds) |>
  precision(truth = TARGET, estimate = predictions)

val_strat |>
  mutate(predictions = preds) |>
  recall(truth = TARGET, estimate = predictions)
```

### LDA
 
```{r}
# define model
lda_mod <- discrim_linear() |>
  set_mode("classification") |>
  set_engine("MASS")
```

Best-performing LDA model: 

```{r}
lda_rec <- recipe(TARGET ~ ., data = train_strat) |>
  step_rm(SK_ID_CURR, AMT_INCOME_TOTAL, AMT_CREDIT, NUM_CREDITS,
          REGION_POPULATION_RELATIVE, CODE_GENDER, AGE_GROUPS, HOUSING_TYPE_OWN,
          HOUSING_TYPE_PARENTS, FLAG_OWN_CAR) |>
  step_mutate(TARGET = factor(TARGET)) |>
  step_dummy(all_nominal_predictors()) |>
  step_zv(all_predictors())

lda_wkflow <- workflow() |>
  add_model(lda_mod) |>
  add_recipe(lda_rec)

lda_fit <- lda_wkflow |>
  fit(train_strat) |>
  extract_fit_parsnip()

preds <- predict(lda_fit, new_data = val_strat)$.pred_class

val_strat |>
  mutate(predictions = preds) |>
  precision(truth = TARGET, estimate = predictions)

val_strat |>
  mutate(predictions = preds) |>
  recall(truth = TARGET, estimate = predictions)
```

Logistic Model has the highest recall, so we choose that model. 
We will now evaluate on test set for performance metrics.

## Test Set

```{r}
preds <- predict(logistic_fit, new_data = test_strat)$.pred_class

test_strat |>
  mutate(predictions = preds) |>
  precision(truth = TARGET, estimate = predictions)

test_strat |>
  mutate(predictions = preds) |>
  recall(truth = TARGET, estimate = predictions)
```

```{r}
calc_fairness_metrics(test_strat$CODE_GENDER, as.numeric(as.character(test_strat$TARGET)), as.numeric(as.character(preds)), no_class = 0)
```


```{r}
calc_fairness_metrics(test_strat$AGE_GROUPS, as.numeric(as.character(test_strat$TARGET)), as.numeric(as.character(preds)), no_class = 0)
```
Model is not fair with regard to age groups because DAYS_EMPLOYED is used as
predictor, so we will remove and evaluate model performance.

```{r}
# need to convert TARGET back
train_strat$TARGET <- ifelse(train_strat$TARGET == -1, 0, 1)
```

```{r}
lg_rec <- recipe(TARGET ~ ., data = train_strat) |>
  step_rm("SK_ID_CURR") |>
  step_rm("AMT_INCOME_TOTAL") |> 
  step_rm("REGION_POPULATION_RELATIVE") |>
  step_rm("INCOME_TO_CREDIT") |>
  step_rm("CNT_CHILDREN") |>
  step_rm("CONTRACT_TYPE_REVOLVING") |>
  step_rm("INCOME_CLASS_FOURTH") |>
  step_rm("INCOME_CLASS_THIRD") |>
  step_rm("INCOME_CLASS_SECOND") |>
  step_rm("CODE_GENDER") |>
  step_rm("AGE_GROUPS") |>
  step_rm("DAYS_EMPLOYED") |>
  step_mutate(TARGET = factor(TARGET, levels=c(0, 1))) |>
  step_dummy(all_nominal_predictors())

logit_wkflow <- workflow() |>
  add_model(logit_mod) |>
  add_recipe(lg_rec)

logistic_fit <- logit_wkflow |>
  fit(train_strat) |>
  extract_fit_parsnip()

preds <- predict(logistic_fit, new_data = test_strat)$.pred_class

test_strat |>
  mutate(predictions = preds) |>
  precision(truth = TARGET, estimate = predictions)

test_strat |>
  mutate(predictions = preds) |>
  recall(truth = TARGET, estimate = predictions)
```


```{r}
calc_fairness_metrics(test_strat$CODE_GENDER, as.numeric(as.character(test_strat$TARGET)), as.numeric(as.character(preds)), no_class = 0)
```


```{r}
calc_fairness_metrics(test_strat$AGE_GROUPS, as.numeric(as.character(test_strat$TARGET)), as.numeric(as.character(preds)), no_class = 0)
```

Model is much more fair with respect to age group, while actually performing 
slightly better with respect to gender as well. 

## Coefficients

```{r}
tidy(logistic_fit)
```

